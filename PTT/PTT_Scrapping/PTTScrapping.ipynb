{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得所有頁面的連結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(driver):\n",
    "    cnt_links = []\n",
    "#     oldest_page = driver.find_element_by_css_selector(\"#action-bar-container > div > div.btn-group.btn-group-paging > a:nth-child(1)\")\n",
    "#     oldest_page.click()\n",
    "\n",
    "    while True:      \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"lxml\")\n",
    "        print(\"link_a\")\n",
    "        links_boxes = soup.find_all('div', class_='title')\n",
    "        links = re.findall('<a href=\"(.*)\">', str(links_boxes))\n",
    "        print(\"link_b\")\n",
    "        url = \"https://www.ptt.cc\"\n",
    "        for link in links:\n",
    "            if len(link)>0:\n",
    "                cnt_links.append(url+link)\n",
    "        print(\"link_c\")\n",
    "        next_page = driver.find_element_by_css_selector(\"#action-bar-container > div > div.btn-group.btn-group-paging > a:nth-child(3)\")\n",
    "        #按到最後一頁不能再按, 但還是顯示在網頁上 可用disabled來判斷\n",
    "        if 'disabled' in next_page.get_attribute('class'):\n",
    "            break;\n",
    "        next_page.click()\n",
    "\n",
    "    return (cnt_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得ppt內文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cnt(soup_cnt):\n",
    "    cnt = soup_cnt.select_one('div#main-content')\n",
    "    selectors_to_del = ['.article-metaline',\n",
    "                       '.article-metaline-right',\n",
    "                        'span.f2',\n",
    "                        'div.push'\n",
    "                       ]\n",
    "\n",
    "    for selector in selectors_to_del:\n",
    "        [tag.extract() for tag in cnt.select(selector)]\n",
    "    x = cnt.text.replace(\"\\n\", \"\")\n",
    "    clean_cnt = re.findall('(.*)--', x)\n",
    "    return(clean_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得連結內容 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnt(client, db, collections, name, driver, cnt_links):\n",
    "    print('get_cnt_a')\n",
    "    print(type(cnt_links))\n",
    "    print(\"版名: \"+ name +\" , 連結數\"+ str(len(cnt_links)))\n",
    "    print('get_cnt_b')\n",
    "    k = 0\n",
    "    \n",
    "    for link in cnt_links:\n",
    "        driver.get(str(link))\n",
    "        html = driver.page_source\n",
    "\n",
    "        soup_cnt = BeautifulSoup(html,\"lxml\")\n",
    "        print(\"get_cnt_c\")\n",
    "        ppt_review = {}\n",
    "\n",
    "\n",
    "        #取得基本資訊\n",
    "        try:\n",
    "            metas = soup_cnt.find_all('div', class_ = 'article-metaline')\n",
    "            ppt_review['title'] = metas[1].text.replace(\"標題\", \"\")\n",
    "            ppt_review['time'] = metas[2].text.replace(\"時間\", \"\")\n",
    "        except IndexError:\n",
    "            ppt_review['title'] = \"\"\n",
    "            ppt_review['time'] = \"\"\n",
    "        print(\"get_cnt_d\")\n",
    "\n",
    "        #取得評論\n",
    "        try:\n",
    "            cmts = soup_cnt.find_all('span', class_ = 'f3 push-content')\n",
    "            ppt_review['cnt'] = []\n",
    "            for cmt in cmts:\n",
    "                x = cmt.text.strip(':')\n",
    "                ppt_review['cnt'].append(x)\n",
    "        except Exception as e:\n",
    "            print (e.__doc__)            \n",
    "            \n",
    "        #取得內文\n",
    "        try:\n",
    "            ppt_review['article'] = inner_cnt(soup_cnt)\n",
    "        except Exception as e:\n",
    "            print (e.__doc__)  \n",
    "        print(\"get_cnt_e\")\n",
    "        \n",
    "        db.ppt_col.insert(ppt_review)\n",
    "\n",
    "        k+=1\n",
    "        print(\"寫入至mongodb第\"+ str(k) +\"筆 \" + name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更換不同header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import json\n",
    "\n",
    "def random_header():\n",
    "    ua = UserAgent()\n",
    "    random_header = json.loads(r'''{\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Host\": \"www.dogforum.com\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"User-Agent\":\"%s\"\n",
    "    }'''%ua.random)\n",
    "    return random_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re \n",
    "from pymongo import MongoClient\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from queue import Queue \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import InvalidElementStateException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "import json\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "def getStart():\n",
    "    #用chrome爬蟲一定要有chromedriver.exe才可以\n",
    "    chrome_path = r\"C:\\Users\\Java\\Desktop\\iii_project\\textmining\\chromedriver.exe\"\n",
    "    \n",
    "    #把不同的args,亦即header加入webdriver中\n",
    "    options = webdriver.ChromeOptions()\n",
    "    args = str(random_header())\n",
    "    options.add_argument(args)\n",
    "    options.add_argument('lang=zh_CN.UTF-8')\n",
    "    driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=options )\n",
    "    n = 1\n",
    "    \n",
    "    #建立與mongo連線, 並創立db和collection\n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "    db = client.ppt_db\n",
    "    collections = db.ppt_col\n",
    "    \n",
    "    while not q.empty():\n",
    "        name = q.get()\n",
    "        #睡 任意0~10秒讓程式速度降下來, 避免被發現是爬蟲 \n",
    "        time.sleep(random.randint(0, 10))\n",
    "        try:\n",
    "            print(threading.current_thread())\n",
    "            print(\"c\")\n",
    "            #開啟google chrome\n",
    "            driver.get(name)\n",
    "            \n",
    "            print(threading.current_thread())\n",
    "            print(\"d\")\n",
    "            \n",
    "            #開始爬內文\n",
    "            cnt_links = get_links(driver)\n",
    "            \n",
    "            print(threading.current_thread())\n",
    "            print(\"e\")\n",
    "            \n",
    "            get_cnt(client, db, collections, name, driver, cnt_links)\n",
    "            \n",
    "            print(threading.current_thread())\n",
    "            print(\"f\")\n",
    "            \n",
    "        except(InvalidElementStateException,NoSuchElementException,WebDriverException,Exception) as e:\n",
    "            print(\"h\")\n",
    "            fail_store_names.append(name)\n",
    "            print(threading.current_thread())\n",
    "            print(\"error:\"+ str(e) + name)\n",
    "            print(e.with_traceback)\n",
    "    driver.close() \n",
    "    end = time.time()\n",
    "    \n",
    "    start_time = time.localtime(start)\n",
    "    end_time = time.localtime(end)\n",
    "    start_project= time.strftime('%Y-%m-%d %H:%M:%S', start_time )\n",
    "    end_project= time.strftime('%Y-%m-%d %H:%M:%S',end_time )\n",
    "    print(start_project)\n",
    "    print(end_project)\n",
    "    print(\"總共花了: \" + str(end - start))\n",
    "    client.close()\n",
    "\n",
    "#開啟多個執行緒\n",
    "def startDriver():\n",
    "    thread_amount = 4 #開4個thread\n",
    "    threads = []\n",
    "    for i in range(thread_amount):  #開thread\n",
    "        t = threading.Thread(target=getStart)\n",
    "        #開始爬蟲\n",
    "        t.start()\n",
    "        threads.append(t)   \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "        \n",
    "\n",
    "\n",
    "#從這裡開始爬蟲\n",
    "start = time.time()\n",
    "fail_store_names = []\n",
    "\n",
    "#建立queue, 把所有的店名塞進queue裡\n",
    "q = Queue(maxsize=0)\n",
    "\n",
    "#ppt健身四大板的連結\n",
    "ppt_boards = ['https://www.ptt.cc/bbs/FITNESS/index.html', \n",
    "             'https://www.ptt.cc/bbs/musclebeach/index.html', \n",
    "             'https://www.ptt.cc/bbs/Aerobics/index.html', \n",
    "             'https://www.ptt.cc/bbs/BeautyBody/index.html']\n",
    "\n",
    "#把四大板的連結全部放入queue中\n",
    "for board in ppt_boards:\n",
    "    q.put(board)\n",
    "\n",
    "#開啟執行緒\n",
    "startDriver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
